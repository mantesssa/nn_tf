{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e422f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3eedb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "ds_path = \"/Users/mantesssa/Projects/nn/nn_tf/BirdVsDrone/\"\n",
    "data_dir = pathlib.Path(ds_path)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.*')))\n",
    "# print(image_count) # 828\n",
    "\n",
    "tree = os.walk(ds_path)\n",
    "\n",
    "fulllist =[]\n",
    "for i in tree:\n",
    "    fulllist.append(i)\n",
    "    \n",
    "listofdronesnames = []\n",
    "for i in fulllist[1][2]:\n",
    "    if i[-4:] =='jpeg' or i[-4:] =='JPEG' or i[-3:] =='png':\n",
    "        listofdronesnames.append(i) \n",
    "listofdroneslabels = [0]*len(listofdronesnames)\n",
    "\n",
    "listofbirdsnames = []\n",
    "for i in fulllist[2][2]:\n",
    "    if i[-4:] =='jpeg' or i[-4:] =='JPEG' or i[-3:] =='png':\n",
    "        listofbirdsnames.append(i) # .DS_Store ???\n",
    "listofbirdslabels = [1]*len(listofbirdsnames)\n",
    "\n",
    "\n",
    "fulllistnames = listofdronesnames + listofbirdsnames\n",
    "fulllistlabels = listofdroneslabels + listofbirdslabels\n",
    "print(len(fulllistnames)) # 825 \n",
    "\n",
    "\n",
    "list_of_img_matrixes = []\n",
    "\n",
    "for i in range(len(fulllistlabels)): # len = 825\n",
    "    if fulllistlabels[i] == 0:\n",
    "        classnamed = \"Drones\"\n",
    "    else:\n",
    "        classnamed = \"Birds\"\n",
    "    img = cv2.imread(ds_path + classnamed + \"/\" + fulllistnames[i])\n",
    "    RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    smallimgb = cv2.resize(RGB_img, (180,180),interpolation=cv2.INTER_CUBIC)\n",
    "    normsmallimg = smallimgb/ 255\n",
    "    list_of_img_matrixes.append(normsmallimg)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "listofindexes = []\n",
    "for i in range(len(fulllistlabels)): # len = 825\n",
    "    listofindexes.append(i)\n",
    "\n",
    "random.shuffle(listofindexes)\n",
    "shuffledlistofindexes = listofindexes\n",
    "# print(len(shuffledlistofindexes)) # 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9414650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = 800 indexes from 0 to 799\n",
    "\n",
    "# 0|   0-39\n",
    "# 1|   40-79\n",
    "# 2|   80-119 \n",
    "# 3|   120-159\n",
    "# 4|   160-199\n",
    "# 5|   200-239\n",
    "# 6|   240-279\n",
    "# 7|   280-319\n",
    "# 8|   320-359\n",
    "# 9|   360-399\n",
    "# 10|  400-439\n",
    "# 11|  440-479\n",
    "# 12|  480-519\n",
    "# 13|  520-559\n",
    "# 14|  560-599\n",
    "# 15|  600-639\n",
    "# 16|  640-679\n",
    "# 17|  680-719\n",
    "# 18|  720-759\n",
    "# 19|  760-799\n",
    "\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "#     'Generates data for Keras'                      shufled list of indexes\n",
    "    def __init__(self, fulllistnames, fulllistlabels, list_IDs, is_validation=False, \n",
    "                 batch_size=40, dim=(None, 180, 180, 3), n_channels=1, n_classes=2):\n",
    "        'Initialization'\n",
    "        self.fulllistnames = fulllistnames\n",
    "        self.fulllistlabels = fulllistlabels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.is_validation = is_validation\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.valid = is_validation\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        self.number_of_batches = int(np.floor(len(self.list_IDs) / self.batch_size))               # 20\n",
    "        self.number_of_valid_indexes = 2                                                           # 2\n",
    "        self.number_of_training_indexes =  self.number_of_batches - self.number_of_valid_indexes   # 18\n",
    "        self.valind_list_of_indexes = []\n",
    "        self.training_list_of_indexes = []\n",
    "        self.valid_index = self.number_of_training_indexes\n",
    "        self.on_epoch_end()\n",
    "      \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        if self.is_validation:\n",
    "            return self.number_of_valid_indexes # 2\n",
    "        else:\n",
    "            return self.number_of_training_indexes # = 18 \n",
    " \n",
    "    def __getitem__(self, index): # index = number of batch from 0 to __len__ \n",
    "        if self.is_validation:#if validation set\n",
    "            indexes = self.valind_list_of_indexes[index*self.batch_size : (index+1)*self.batch_size]      \n",
    "            list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "            X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        else:#if test set\n",
    "            indexes = self.training_list_of_indexes[index*self.batch_size : (index+1)*self.batch_size]\n",
    "            list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "            X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.valid_index == self.number_of_training_indexes:\n",
    "            self.valid_index = 0\n",
    "        else:\n",
    "            self.valid_index += self.number_of_valid_indexes \n",
    "        \n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "        self.valind_list_of_indexes = self.indexes[self.valid_index*self.batch_size:(self.valid_index+self.number_of_valid_indexes)*self.batch_size]\n",
    "        self.training_list_of_indexes = list(set(self.indexes).difference(self.valind_list_of_indexes))\n",
    "\n",
    "        random.shuffle(self.valind_list_of_indexes)\n",
    "        random.shuffle(self.training_list_of_indexes)\n",
    "\n",
    "        # print(\"self.indexes = \",self.indexes[0:100])\n",
    "        # print(\"self.valind_list_of_indexes = \",self.valind_list_of_indexes[0],self.valind_list_of_indexes[-1])\n",
    "        # print(\"self.training_list_of_indexes = \",self.training_list_of_indexes[0],self.training_list_of_indexes[-1])\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        y = []\n",
    "        X = []\n",
    "        for ID in (list_IDs_temp):\n",
    "            classnumber= self.fulllistlabels[ID]\n",
    "            z = list_of_img_matrixes[ID]\n",
    "            X.append(z)\n",
    "            y.append(classnumber) # if drone = 0 if bird = 1\n",
    "        return np.array(X), keras.utils.to_categorical(y,num_classes=None)\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5d4866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 8)\n"
     ]
    }
   ],
   "source": [
    "allinall = np.array([  #  allinall.shape => (3, 3, 3, 8)  \n",
    "    [#                       RGB  chanels\n",
    "    [[0.75, 0.25, 0.25, 0.75, 0.5, 0.5, 1.0, 0.0,]] * 3,      # a11  <= indexes like matrix    first \"pixel\"    \n",
    "    [[1.0, 0.0, 0.5, 0.5, 0.75, 0.25, 0.75, 0.25,]] * 3,      # a12\n",
    "    [[0.75, 0.25, 0.75, 0.25, 1.0, 0.0, 0.5, 0.5,]] * 3,      # a13\n",
    "    ],\n",
    "#####\n",
    "    [\n",
    "    [[0.5, 0.5, 0.0, 1.0, 0.25, 0.75, 0.75, 0.25,]] * 3,      # a21\n",
    "    [[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,]] * 3,         # a22\n",
    "    [[0.5, 0.5, 1.0, 0.0, 0.75, 0.25, 0.25, 0.75,]] * 3,      # a23\n",
    "    ],\n",
    "#####\n",
    "    [\n",
    "    [[0.25, 0.75, 0.25, 0.75, 0.0, 1.0, 0.5, 0.5,]] * 3,      # a31\n",
    "    [[0.0, 1.0, 0.5, 0.5, 0.25, 0.75, 0.25, 0.75,]] * 3,      # a32\n",
    "    [[0.25, 0.75, 0.75, 0.25, 0.5, 0.5, 0.0, 1.0,]] * 3,      # a33\n",
    "    ],\n",
    "    ], dtype= np.float32)\n",
    "\n",
    "\n",
    "print(allinall.shape)\n",
    "# allinall = tf.convert_to_tensor(allinall)\n",
    "# print(allinall)\n",
    "initializer = tf.keras.initializers.Constant(allinall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38143da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "\n",
    "# Defining model input\n",
    "input_ =  tf.keras.Input(shape=(180, 180, 3))\n",
    "\n",
    "# Defining first parallel layer\n",
    "in_1 = tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same', name=\"initializer_on\", kernel_initializer=initializer)(input_)\n",
    "# conv_1 = tf.keras.layers.BatchNormalization()(in_1)\n",
    "# conv_1 = AveragePooling2D(pool_size=(2, 2), strides=(3, 3))(conv_1)\n",
    "\n",
    "\n",
    "# Defining second parallel layer\n",
    "in_2 = tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same', name=\"initializer_off\")(input_)\n",
    "\n",
    "# Concatenating layers\n",
    "concat = tf.keras.layers.concatenate([in_1, in_2])\n",
    "# concat = tf.keras.layers.concatenate([conv_1, conv_2])\n",
    "\n",
    "\n",
    "minimodel = Model(inputs=[input_], outputs=[concat], name=\"allinall\")\n",
    "# minimodel.summary()\n",
    "\n",
    "\n",
    "# for layer in filter(lambda x: 'initializer_on' in x.name, minimodel.layers):\n",
    "#     weights, bias = map(lambda x: x, layer.get_weights())\n",
    "    # layer.set_weights([allinall, bias])\n",
    "    # print(\"weights = \", tf.is_tensor(weights))\n",
    "    # print(\"weights = \", weights)\n",
    "    # print(\"bias =\",bias)\n",
    "    # print(initializer)\n",
    "\n",
    "    # weights_shape, bias_shape = map(lambda x: x.shape, layer.get_weights())\n",
    "    # print(\"weights_shape\",weights_shape)\n",
    "    # print(\"bias_shape\",bias_shape)\n",
    "    # # print(np.full(weights_shape,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4105d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "class_names = ['Drones', 'Birds']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# need to ad data augmintation to mobile net vesion\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n",
    "    layers.RandomRotation(0.12),\n",
    "    layers.RandomZoom(0.3),\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "# vgg4 == visual geometry group 4 # OLD\n",
    "# model = Sequential([\n",
    "#   data_augmentation,\n",
    "#   layers.Rescaling(1./255),\n",
    "#   minimodel,\n",
    "#   layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Dropout(0.15), # 0.1 work not so well\n",
    "#   layers.Flatten(),\n",
    "#   layers.Dense(128, activation='relu'),\n",
    "#   layers.Dense(num_classes, name=\"outputs\", activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# MOBILE_NET_V3\n",
    "model = tf.keras.applications.MobileNetV3Small(\n",
    "\t\tinput_shape=(180,180,3),\n",
    "    alpha=1.0,\n",
    "    minimalistic=False,\n",
    "\t\tinclude_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    classes=num_classes,\n",
    "\t\tpooling=None,\n",
    "    classifier_activation=\"softmax\",\n",
    "\t\tinclude_preprocessing=True\n",
    "    )\n",
    "\n",
    "\n",
    "# model.summary() # too big "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e64d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch < 25:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.9)\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              # loss='binary_crossentropy',\n",
    "              loss='categorical_crossentropy',\n",
    "              # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab6afeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 22s 893ms/step - loss: 0.7257 - accuracy: 0.6389 - val_loss: 0.6935 - val_accuracy: 0.4625 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 15s 821ms/step - loss: 0.5904 - accuracy: 0.7153 - val_loss: 0.6944 - val_accuracy: 0.4750 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 15s 819ms/step - loss: 0.4393 - accuracy: 0.7986 - val_loss: 0.6949 - val_accuracy: 0.4875 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 15s 815ms/step - loss: 0.3856 - accuracy: 0.8222 - val_loss: 0.6871 - val_accuracy: 0.5875 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 14s 794ms/step - loss: 0.3528 - accuracy: 0.8556 - val_loss: 0.6977 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 14s 785ms/step - loss: 0.3419 - accuracy: 0.8486 - val_loss: 0.7031 - val_accuracy: 0.4125 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 14s 783ms/step - loss: 0.2697 - accuracy: 0.8972 - val_loss: 0.6908 - val_accuracy: 0.5375 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 14s 777ms/step - loss: 0.2070 - accuracy: 0.9167 - val_loss: 0.6919 - val_accuracy: 0.5250 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 14s 794ms/step - loss: 0.2410 - accuracy: 0.9014 - val_loss: 0.7107 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 14s 777ms/step - loss: 0.2144 - accuracy: 0.9097 - val_loss: 0.7002 - val_accuracy: 0.4625 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "#FIT#############################################################################################################\n",
    "\n",
    "params = {'dim': (None, 180, 180, 3),\n",
    "          'batch_size': 40,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 1,}\n",
    "\n",
    "training_generator = DataGenerator(fulllistnames,fulllistlabels,shuffledlistofindexes,False, **params)\n",
    "validation_generator = DataGenerator(fulllistnames,fulllistlabels,shuffledlistofindexes,True, **params)\n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"/Users/mantesssa/Projects/nn/nn_tf/logs\")\n",
    "\n",
    "epochs = 10 # n*10\n",
    "history = model.fit(training_generator,\n",
    "          validation_data=validation_generator,\n",
    "          epochs=epochs,\n",
    "          callbacks=[tensorboard_callback,callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c4962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"/Users/mantesssa/Projects/nn/nn_tf/my_model_100e_dropout015\")# worked saved all model \n",
    "# model.save_weights(\"/Users/mantesssa/Projects/nn/nn_tf/checkpoints/my_checkpoint_dropout015\") # worked saved in checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025112f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"/Users/mantesssa/Projects/nn/nn_tf/my_model_100e\")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "225fb183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d (3, 3, 16, 16)\n",
      "conv2d_1 (3, 3, 16, 32)\n",
      "conv2d_2 (3, 3, 32, 64)\n",
      "conv2d_3 (3, 3, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "# # summarize filters in each convolutional layer\n",
    "\n",
    "# summarize filter shapes\n",
    "\n",
    "for layer in model.layers:\n",
    "  # check for convolutional layer\n",
    "  if 'conv' not in layer.name:\n",
    "    continue\n",
    "  # get filter weights\n",
    "  filters, biases = layer.get_weights()\n",
    "  print(layer.name, filters.shape)\n",
    "\n",
    "# We can see that all convolutional layers use 3×3 filters, which are small and perhaps easy to interpret.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bc74c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = tf.keras.models.load_model(\"/Users/mantesssa/Projects/nn/nn_tf/my_model_100e\")\n",
    "# new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = tf.keras.models.load_model(\"/Users/mantesssa/Projects/nn/nn_tf/my_model_100e\")\n",
    "# new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3316d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "test_path = \"/Users/mantesssa/Projects/nn/nn_tf/test/\"    # it works \n",
    "\n",
    "tree = os.walk(test_path)\n",
    "\n",
    "fulllist = []\n",
    "for i in tree:\n",
    "    fulllist.append(i)\n",
    "    \n",
    "listofdronesnames = []\n",
    "for i in fulllist[1][2]:\n",
    "    if i[-4:] =='jpeg' or i[-4:] =='JPEG' or i[-3:] =='png':\n",
    "        listofdronesnames.append(i)\n",
    "listofdroneslabels = [0]*len(listofdronesnames)\n",
    "\n",
    "listofbirdsnames = []\n",
    "for i in fulllist[2][2]:\n",
    "    if i[-4:] =='jpeg' or i[-4:] =='JPEG' or i[-3:] =='png':\n",
    "        listofbirdsnames.append(i) # .DS_Store ???\n",
    "listofbirdslabels = [1]*len(listofbirdsnames)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fulllistnames = listofdronesnames + listofbirdsnames\n",
    "fulllistlabels = listofdroneslabels + listofbirdslabels\n",
    "print(len(fulllistnames)) # 825 \n",
    "print(len(fulllistlabels)) # 825 \n",
    "\n",
    "\n",
    "# list_of_test_img_matrixes = []\n",
    "\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "for i in range(len(fulllistlabels)): # len = 825\n",
    "    if fulllistlabels[i] == 0:\n",
    "        classnamed = \"Drones\"\n",
    "    else:\n",
    "        classnamed = \"Birds\"\n",
    "    img_path = test_path + classnamed + \"/\" + fulllistnames[i]\n",
    "\n",
    "\n",
    "    img = tf.keras.utils.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) #  Create a batch\n",
    "\n",
    "\n",
    "    predictions = new_model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    print(img_path)\n",
    "    print(\n",
    "    \"____ {} ______ with a {:.2f}% confidence.\"\n",
    "    # \"This image most likely belongs to ____ {} ______ with a {:.2f}% confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15e30782",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################### pre loaded images version \n",
    "list_of_test_img_matrixes = []\n",
    "\n",
    "for i in range(len(fulllistlabels)): # len = 825\n",
    "    true_label_num = fulllistlabels[i]\n",
    "    if true_label_num == 0:\n",
    "        classnamed = \"Drones\"\n",
    "    else:\n",
    "        classnamed = \"Birds\"\n",
    "    path_to_img = test_path + classnamed + \"/\" + fulllistnames[i]\n",
    "\n",
    "    # img = cv2.imread(path_to_img)\n",
    "    # RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # smallimgb = cv2.resize(RGB_img, (180,180),interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    img = tf.keras.utils.load_img(path_to_img, target_size=(img_height, img_width))\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) #  Create a batch\n",
    "    # print(img_array.shape)\n",
    "\n",
    "    # img_path = test_path + classnamed + \"/\" + fulllistnames[i]\n",
    "    # img = tf.keras.utils.load_img(img_path, target_size=(img_height, img_width))\n",
    "    # img_array = tf.keras.utils.img_to_array(img)\n",
    "    # img_array = tf.expand_dims(img_array, 0) #  Create a batch\n",
    "    # predictions = new_model.predict(img_array)\n",
    "\n",
    "    # normsmallimg = smallimgb/ 255.\n",
    "    list_of_test_img_matrixes.append([img_array, true_label_num]) #?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_class_num =0\n",
    "for i in range(len(fulllistlabels)): # len = 825\n",
    "    # if fulllistlabels[i] == 0:\n",
    "    #     classnamed = \"Drones\"\n",
    "    # else:\n",
    "    #     classnamed = \"Birds\"\n",
    "    # img_path = test_path + classnamed + \"/\" + fulllistnames[i]\n",
    "\n",
    "\n",
    "    # img = tf.keras.utils.load_img(img_path, target_size=(img_height, img_width))\n",
    "    test_img = list_of_test_img_matrixes[i][0]\n",
    "    label_num = list_of_test_img_matrixes[i][1]\n",
    "    # plt.imshow(test_img)\n",
    "    # plt.show()\n",
    "    # print (np.array(test_img).shape)\n",
    "    # print (label_num)\n",
    "\n",
    "    # img_array = tf.keras.utils.img_to_array(test_img)\n",
    "    # img_array = tf.expand_dims(img_array, 0) #  Create a batch\n",
    "\n",
    "    predictions = new_model.predict(test_img)\n",
    "    tf.keras.backend.clear_session()\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    if label_num == np.argmax(score):\n",
    "        false_class_num += 1\n",
    "    print(\n",
    "    \"This image most likely belongs to {} with a {:.2f}% confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    )\n",
    "\n",
    "print(\"test_accuracy = \",false_class_num/len(fulllistlabels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
