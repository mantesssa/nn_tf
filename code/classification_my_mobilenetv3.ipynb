{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e422f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3eedb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801\n"
     ]
    }
   ],
   "source": [
    "ds_path = \"/Users/mantesssa/Projects/nn/nn_tf/BirdVsDrone/\"\n",
    "data_dir = pathlib.Path(ds_path)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.*')))\n",
    "# print(image_count) # 828\n",
    "\n",
    "tree = os.walk(ds_path)\n",
    "\n",
    "fulllist =[]\n",
    "for i in tree:\n",
    "    fulllist.append(i)\n",
    "    \n",
    "listofdronesnames = []\n",
    "for i in fulllist[1][2]:\n",
    "    if i[-4:] =='jpeg' or i[-4:] =='JPEG' or i[-3:] =='png':\n",
    "        listofdronesnames.append(i) \n",
    "listofdroneslabels = [0]*len(listofdronesnames)\n",
    "\n",
    "listofbirdsnames = []\n",
    "for i in fulllist[2][2]:\n",
    "    if i[-4:] =='jpeg' or i[-4:] =='JPEG' or i[-3:] =='png':\n",
    "        listofbirdsnames.append(i) # .DS_Store ???\n",
    "listofbirdslabels = [1]*len(listofbirdsnames)\n",
    "\n",
    "\n",
    "fulllistnames = listofdronesnames + listofbirdsnames\n",
    "fulllistlabels = listofdroneslabels + listofbirdslabels\n",
    "print(len(fulllistnames)) # 825 \n",
    "\n",
    "\n",
    "list_of_img_matrixes = []\n",
    "\n",
    "for i in range(len(fulllistlabels)): # len = 825\n",
    "    if fulllistlabels[i] == 0:\n",
    "        classnamed = \"Drones\"\n",
    "    else:\n",
    "        classnamed = \"Birds\"\n",
    "    img = cv2.imread(ds_path + classnamed + \"/\" + fulllistnames[i])\n",
    "    RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    smallimgb = cv2.resize(RGB_img, (180,180),interpolation=cv2.INTER_CUBIC)\n",
    "    normsmallimg = smallimgb/ 255\n",
    "    list_of_img_matrixes.append(normsmallimg)\n",
    "        \n",
    "    \n",
    "\n",
    "listofindexes = []\n",
    "for i in range(len(fulllistlabels)): # len = 825\n",
    "    listofindexes.append(i)\n",
    "\n",
    "random.shuffle(listofindexes)\n",
    "shuffledlistofindexes = listofindexes\n",
    "# print(len(shuffledlistofindexes)) # 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9414650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = 800 indexes from 0 to 799\n",
    "\n",
    "# 0|   0-39\n",
    "# 1|   40-79\n",
    "# 2|   80-119 \n",
    "# 3|   120-159\n",
    "# 4|   160-199\n",
    "# 5|   200-239\n",
    "# 6|   240-279\n",
    "# 7|   280-319\n",
    "# 8|   320-359\n",
    "# 9|   360-399\n",
    "# 10|  400-439\n",
    "# 11|  440-479\n",
    "# 12|  480-519\n",
    "# 13|  520-559\n",
    "# 14|  560-599\n",
    "# 15|  600-639\n",
    "# 16|  640-679\n",
    "# 17|  680-719\n",
    "# 18|  720-759\n",
    "# 19|  760-799\n",
    "\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "#     'Generates data for Keras'                      shufled list of indexes\n",
    "    def __init__(self, fulllistnames, fulllistlabels, list_IDs, is_validation=False, \n",
    "                 batch_size=40, dim=(None, 180, 180, 3), n_channels=1, n_classes=2):\n",
    "        'Initialization'\n",
    "        self.fulllistnames = fulllistnames\n",
    "        self.fulllistlabels = fulllistlabels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.is_validation = is_validation\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.valid = is_validation\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        self.number_of_batches = int(np.floor(len(self.list_IDs) / self.batch_size))               # 20\n",
    "        self.number_of_valid_indexes = 2                                                           # 2\n",
    "        self.number_of_training_indexes =  self.number_of_batches - self.number_of_valid_indexes   # 18\n",
    "        self.valind_list_of_indexes = []\n",
    "        self.training_list_of_indexes = []\n",
    "        self.valid_index = self.number_of_training_indexes\n",
    "        self.on_epoch_end()\n",
    "      \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        if self.is_validation:\n",
    "            return self.number_of_valid_indexes # 2\n",
    "        else:\n",
    "            return self.number_of_training_indexes # = 18 \n",
    " \n",
    "    def __getitem__(self, index): # index = number of batch from 0 to __len__ \n",
    "        if self.is_validation:#if validation set\n",
    "            indexes = self.valind_list_of_indexes[index*self.batch_size : (index+1)*self.batch_size]      \n",
    "            list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "            X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        else:#if test set\n",
    "            indexes = self.training_list_of_indexes[index*self.batch_size : (index+1)*self.batch_size]\n",
    "            list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "            X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.valid_index == self.number_of_training_indexes:\n",
    "            self.valid_index = 0\n",
    "        else:\n",
    "            self.valid_index += self.number_of_valid_indexes \n",
    "        \n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "        self.valind_list_of_indexes = self.indexes[self.valid_index*self.batch_size:(self.valid_index+self.number_of_valid_indexes)*self.batch_size]\n",
    "        self.training_list_of_indexes = list(set(self.indexes).difference(self.valind_list_of_indexes))\n",
    "\n",
    "        random.shuffle(self.valind_list_of_indexes)\n",
    "        random.shuffle(self.training_list_of_indexes)\n",
    "\n",
    "        # print(\"self.indexes = \",self.indexes[0:100])\n",
    "        # print(\"self.valind_list_of_indexes = \",self.valind_list_of_indexes[0],self.valind_list_of_indexes[-1])\n",
    "        # print(\"self.training_list_of_indexes = \",self.training_list_of_indexes[0],self.training_list_of_indexes[-1])\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        y = []\n",
    "        X = []\n",
    "        for ID in (list_IDs_temp):\n",
    "            classnumber= self.fulllistlabels[ID]\n",
    "            z = list_of_img_matrixes[ID]\n",
    "            X.append(z)\n",
    "            y.append(classnumber) # if drone = 0 if bird = 1\n",
    "        return np.array(X), keras.utils.to_categorical(y,num_classes=None)\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5d4866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 8)\n"
     ]
    }
   ],
   "source": [
    "allinall = np.array([  #  allinall.shape => (3, 3, 3, 8)  \n",
    "    [#                       RGB  chanels\n",
    "    [[0.75, 0.25, 0.25, 0.75, 0.5, 0.5, 1.0, 0.0,]] * 3,      # a11  <= indexes like matrix    first \"pixel\"    \n",
    "    [[1.0, 0.0, 0.5, 0.5, 0.75, 0.25, 0.75, 0.25,]] * 3,      # a12\n",
    "    [[0.75, 0.25, 0.75, 0.25, 1.0, 0.0, 0.5, 0.5,]] * 3,      # a13\n",
    "    ],\n",
    "#####\n",
    "    [\n",
    "    [[0.5, 0.5, 0.0, 1.0, 0.25, 0.75, 0.75, 0.25,]] * 3,      # a21\n",
    "    [[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,]] * 3,         # a22\n",
    "    [[0.5, 0.5, 1.0, 0.0, 0.75, 0.25, 0.25, 0.75,]] * 3,      # a23\n",
    "    ],\n",
    "#####\n",
    "    [\n",
    "    [[0.25, 0.75, 0.25, 0.75, 0.0, 1.0, 0.5, 0.5,]] * 3,      # a31\n",
    "    [[0.0, 1.0, 0.5, 0.5, 0.25, 0.75, 0.25, 0.75,]] * 3,      # a32\n",
    "    [[0.25, 0.75, 0.75, 0.25, 0.5, 0.5, 0.0, 1.0,]] * 3,      # a33\n",
    "    ],\n",
    "    ], dtype= np.float32)\n",
    "\n",
    "\n",
    "print(allinall.shape)\n",
    "# allinall = tf.convert_to_tensor(allinall)\n",
    "# print(allinall)\n",
    "initializer = tf.keras.initializers.Constant(allinall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38143da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "\n",
    "# Defining model input\n",
    "input_ =  tf.keras.Input(shape=(180, 180, 3))\n",
    "\n",
    "# Defining first parallel layer\n",
    "in_1 = tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same', name=\"initializer_on\", kernel_initializer=initializer)(input_)\n",
    "# conv_1 = tf.keras.layers.BatchNormalization()(in_1)\n",
    "# conv_1 = AveragePooling2D(pool_size=(2, 2), strides=(3, 3))(conv_1)\n",
    "\n",
    "\n",
    "# Defining second parallel layer\n",
    "in_2 = tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same', name=\"initializer_off\")(input_)\n",
    "\n",
    "# Concatenating layers\n",
    "concat = tf.keras.layers.concatenate([in_1, in_2])\n",
    "# concat = tf.keras.layers.concatenate([conv_1, conv_2])\n",
    "\n",
    "\n",
    "minimodel = Model(inputs=[input_], outputs=[concat], name=\"allinall\")\n",
    "# minimodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4105d10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 180, 180, 3)]     0         \n",
      "                                                                 \n",
      " random_flip_10 (RandomFlip)  (None, 180, 180, 3)      0         \n",
      "                                                                 \n",
      " random_rotation_10 (RandomR  (None, 180, 180, 3)      0         \n",
      " otation)                                                        \n",
      "                                                                 \n",
      " random_zoom_10 (RandomZoom)  (None, 180, 180, 3)      0         \n",
      "                                                                 \n",
      " MobilenetV3small (Functiona  (None, 2)                450586    \n",
      " l)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 450,586\n",
      "Trainable params: 445,146\n",
      "Non-trainable params: 5,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 40\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "class_names = ['Drones', 'Birds']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# data_augmentation = keras.Sequential(\n",
    "#   [\n",
    "#     layers.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n",
    "#     layers.RandomRotation(0.12),\n",
    "#     layers.RandomZoom(0.3),\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "# MOBILE_NET_V3\n",
    "# if alpha = 1.0 => 2kk parameters\n",
    "# if alpha = 0.5 => 570k parameters\n",
    "# if alpha = 0.4 => 445k parameters\n",
    "# if alpha = 0.3 => 327k parameters\n",
    "# if alpha = 0.2 => 230k parameters\n",
    "# if alpha = 0.1 => 144k parameters\n",
    "# if alpha = 0.0 =>  79k parameters\n",
    "\n",
    "\n",
    "# model = tf.keras.applications.MobileNetV3Small(\n",
    "# \t\tinput_shape=(180,180,3),\n",
    "#     alpha=0.0,    \n",
    "#     minimalistic=False,\n",
    "# \t\tinclude_top=True,\n",
    "#     weights=None,\n",
    "#     input_tensor=None,\n",
    "#     classes=num_classes,\n",
    "# \t\tpooling=None,\n",
    "#     classifier_activation=\"softmax\",\n",
    "# \t\tinclude_preprocessing=True\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MobileNetV3Small model with data augmentation\n",
    "base_model = tf.keras.applications.MobileNetV3Small(\n",
    "\t\tinput_shape=(180,180,3),\n",
    "    alpha=0.4,    \n",
    "    minimalistic=False,\n",
    "\t\tinclude_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    classes=num_classes,\n",
    "\t\tpooling=None,\n",
    "    classifier_activation=\"softmax\",\n",
    "\t\tinclude_preprocessing=True\n",
    "    )\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=(180, 180, 3))\n",
    "x = layers.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3))(inputs)\n",
    "x = layers.RandomRotation(0.12)(x)\n",
    "x = layers.RandomZoom(0.3)(x)\n",
    "x = base_model(x)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.summary() # too big "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e64d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch < 25:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.9)\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              # loss='binary_crossentropy',\n",
    "              loss='categorical_crossentropy',\n",
    "              # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab6afeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 12s 631ms/step - loss: 0.6205 - accuracy: 0.6889 - val_loss: 0.6944 - val_accuracy: 0.4250 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 10s 560ms/step - loss: 0.5204 - accuracy: 0.7417 - val_loss: 0.6982 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 3/10\n",
      " 4/18 [=====>........................] - ETA: 7s - loss: 0.4417 - accuracy: 0.7812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m tensorboard_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(log_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/Users/mantesssa/Projects/nn/nn_tf/logs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39m# n*10\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(training_generator,\n\u001b[1;32m     16\u001b[0m           validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[1;32m     17\u001b[0m           epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     18\u001b[0m           callbacks\u001b[39m=\u001b[39;49m[tensorboard_callback,callback])\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.10/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.10/envs/tf/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.10/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.10/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.10/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.10/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.10/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.10/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.10/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#FIT#############################################################################################################\n",
    "\n",
    "params = {'dim': (None, 180, 180, 3),\n",
    "          'batch_size': 40,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 1,}\n",
    "\n",
    "training_generator = DataGenerator(fulllistnames,fulllistlabels,shuffledlistofindexes,False, **params)\n",
    "validation_generator = DataGenerator(fulllistnames,fulllistlabels,shuffledlistofindexes,True, **params)\n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"/Users/mantesssa/Projects/nn/nn_tf/logs\")\n",
    "\n",
    "epochs = 10 # n*10\n",
    "history = model.fit(training_generator,\n",
    "          validation_data=validation_generator,\n",
    "          epochs=epochs,\n",
    "          callbacks=[tensorboard_callback,callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c4962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"/Users/mantesssa/Projects/nn/nn_tf/my_model_100e_dropout015\")# worked saved all model \n",
    "# model.save_weights(\"/Users/mantesssa/Projects/nn/nn_tf/checkpoints/my_checkpoint_dropout015\") # worked saved in checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025112f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"/Users/mantesssa/Projects/nn/nn_tf/my_model_100e\")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "225fb183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d (3, 3, 16, 16)\n",
      "conv2d_1 (3, 3, 16, 32)\n",
      "conv2d_2 (3, 3, 32, 64)\n",
      "conv2d_3 (3, 3, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "# # summarize filters in each convolutional layer\n",
    "\n",
    "# summarize filter shapes\n",
    "\n",
    "for layer in model.layers:\n",
    "  # check for convolutional layer\n",
    "  if 'conv' not in layer.name:\n",
    "    continue\n",
    "  # get filter weights\n",
    "  filters, biases = layer.get_weights()\n",
    "  print(layer.name, filters.shape)\n",
    "\n",
    "# We can see that all convolutional layers use 3×3 filters, which are small and perhaps easy to interpret.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bc74c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = tf.keras.models.load_model(\"/Users/mantesssa/Projects/nn/nn_tf/my_model_100e\")\n",
    "# new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = tf.keras.models.load_model(\"/Users/mantesssa/Projects/nn/nn_tf/my_model_100e\")\n",
    "# new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3316d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "test_path = \"/Users/mantesssa/Projects/nn/nn_tf/test/\"    # it works \n",
    "\n",
    "tree = os.walk(test_path)\n",
    "\n",
    "fulllist = []\n",
    "for i in tree:\n",
    "    fulllist.append(i)\n",
    "    \n",
    "listofdronesnames = []\n",
    "for i in fulllist[1][2]:\n",
    "    if i[-4:] =='jpeg' or i[-4:] =='JPEG' or i[-3:] =='png':\n",
    "        listofdronesnames.append(i)\n",
    "listofdroneslabels = [0]*len(listofdronesnames)\n",
    "\n",
    "listofbirdsnames = []\n",
    "for i in fulllist[2][2]:\n",
    "    if i[-4:] =='jpeg' or i[-4:] =='JPEG' or i[-3:] =='png':\n",
    "        listofbirdsnames.append(i) # .DS_Store ???\n",
    "listofbirdslabels = [1]*len(listofbirdsnames)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fulllistnames = listofdronesnames + listofbirdsnames\n",
    "fulllistlabels = listofdroneslabels + listofbirdslabels\n",
    "print(len(fulllistnames)) # 825 \n",
    "print(len(fulllistlabels)) # 825 \n",
    "\n",
    "\n",
    "# list_of_test_img_matrixes = []\n",
    "\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "for i in range(len(fulllistlabels)): # len = 825\n",
    "    if fulllistlabels[i] == 0:\n",
    "        classnamed = \"Drones\"\n",
    "    else:\n",
    "        classnamed = \"Birds\"\n",
    "    img_path = test_path + classnamed + \"/\" + fulllistnames[i]\n",
    "\n",
    "\n",
    "    img = tf.keras.utils.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) #  Create a batch\n",
    "\n",
    "\n",
    "    predictions = new_model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    print(img_path)\n",
    "    print(\n",
    "    \"____ {} ______ with a {:.2f}% confidence.\"\n",
    "    # \"This image most likely belongs to ____ {} ______ with a {:.2f}% confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15e30782",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################### pre loaded images version \n",
    "list_of_test_img_matrixes = []\n",
    "\n",
    "for i in range(len(fulllistlabels)): # len = 825\n",
    "    true_label_num = fulllistlabels[i]\n",
    "    if true_label_num == 0:\n",
    "        classnamed = \"Drones\"\n",
    "    else:\n",
    "        classnamed = \"Birds\"\n",
    "    path_to_img = test_path + classnamed + \"/\" + fulllistnames[i]\n",
    "\n",
    "    # img = cv2.imread(path_to_img)\n",
    "    # RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # smallimgb = cv2.resize(RGB_img, (180,180),interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    img = tf.keras.utils.load_img(path_to_img, target_size=(img_height, img_width))\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) #  Create a batch\n",
    "    # print(img_array.shape)\n",
    "\n",
    "    # img_path = test_path + classnamed + \"/\" + fulllistnames[i]\n",
    "    # img = tf.keras.utils.load_img(img_path, target_size=(img_height, img_width))\n",
    "    # img_array = tf.keras.utils.img_to_array(img)\n",
    "    # img_array = tf.expand_dims(img_array, 0) #  Create a batch\n",
    "    # predictions = new_model.predict(img_array)\n",
    "\n",
    "    # normsmallimg = smallimgb/ 255.\n",
    "    list_of_test_img_matrixes.append([img_array, true_label_num]) #?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_class_num =0\n",
    "for i in range(len(fulllistlabels)): # len = 825\n",
    "\n",
    "    # img = tf.keras.utils.load_img(img_path, target_size=(img_height, img_width))\n",
    "    test_img = list_of_test_img_matrixes[i][0]\n",
    "    label_num = list_of_test_img_matrixes[i][1]\n",
    "    # plt.imshow(test_img)\n",
    "    # plt.show()\n",
    "    # print (np.array(test_img).shape)\n",
    "    # print (label_num)\n",
    "\n",
    "    # img_array = tf.keras.utils.img_to_array(test_img)\n",
    "    # img_array = tf.expand_dims(img_array, 0) #  Create a batch\n",
    "\n",
    "    predictions = new_model.predict(test_img)\n",
    "    tf.keras.backend.clear_session()\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    if label_num == np.argmax(score):\n",
    "        false_class_num += 1\n",
    "    print(\n",
    "    \"This image most likely belongs to {} with a {:.2f}% confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    )\n",
    "\n",
    "print(\"test_accuracy = \",false_class_num/len(fulllistlabels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
